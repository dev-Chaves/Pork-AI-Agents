import os
import json
import requests
from datetime import datetime, timezone
from dotenv import load_dotenv
from openai import OpenAI

from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool

# Carrega as vari√°veis de ambiente (.env)
load_dotenv()

# Valida√ß√£o das vari√°veis essenciais
required_vars = ["OPENAI_API_KEY", "API_BASE_URL", "MONITORING_API_KEY"]
missing = [k for k in required_vars if not os.getenv(k)]
if missing:
    raise RuntimeError(f"Vari√°veis ausentes no .env: {', '.join(missing)}")

# =========================================
# Configura√ß√£o do RouteLLM (Abacus.AI)
# =========================================
client = OpenAI(
    base_url="https://routellm.abacus.ai/v1",
    api_key=os.getenv("OPENAI_API_KEY"),  # sua chave do Abacus
)

def route_llm(messages, **kwargs):
    """
    Wrapper para usar RouteLLM com CrewAI.
    Aceita messages e retorna resposta do modelo.
    """
    # Se receber string, converte para formato de mensagens
    if isinstance(messages, str):
        messages = [{"role": "user", "content": messages}]
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # ou outro modelo v√°lido do RouteLLM
            messages=messages,
            temperature=kwargs.get("temperature", 0),
            max_tokens=kwargs.get("max_tokens", 1000),
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Erro na chamada LLM: {str(e)}"

# === PERSIST√äNCIA DE LOGS ===
LOG_FILE = "monitoring_logs.json"

def persist_data(entry: dict):
    """Salva os resultados em JSON (append)."""
    try:
        if not os.path.exists(LOG_FILE):
            with open(LOG_FILE, "w", encoding="utf-8") as f:
                json.dump([], f)
        with open(LOG_FILE, "r+", encoding="utf-8") as f:
            data = json.load(f)
            data.append(entry)
            f.seek(0)
            json.dump(data, f, indent=2, ensure_ascii=False)
            f.truncate()
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao salvar log: {e}")

# --- FERRAMENTA CUSTOM ---
class ApiMonitoringTool(BaseTool):
    """
    Ferramenta para requisi√ß√µes aos endpoints de monitoramento da API.
    Usa API_BASE_URL e MONITORING_API_KEY do .env.
    """
    name: str = "API Monitoring Tool"
    description: str = "Faz GET em endpoints de monitoramento e retorna o texto da resposta."

    def _run(self, endpoint: str) -> str:
        api_base_url = os.getenv("API_BASE_URL")
        api_key = os.getenv("MONITORING_API_KEY")

        if not api_base_url or not api_key:
            return "Erro: Vari√°veis API_BASE_URL ou MONITORING_API_KEY n√£o definidas."

        headers = {
            "Content-Type": "application/json",
            "X-API-KEY": api_key
        }

        try:
            # Normaliza URL
            url = f"{api_base_url.rstrip('/')}/{endpoint.lstrip('/')}"
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            # Tenta retornar JSON formatado, sen√£o texto puro
            try:
                return json.dumps(response.json(), ensure_ascii=False, indent=2)
            except:
                return response.text
                
        except requests.exceptions.Timeout:
            return f"Erro: Timeout ao acessar {endpoint}"
        except requests.exceptions.HTTPError as e:
            return f"Erro HTTP em {endpoint}: {response.status_code} - {e}"
        except requests.exceptions.RequestException as e:
            return f"Erro geral ao acessar {endpoint}: {e}"

# Inst√¢ncia da ferramenta
api_tool = ApiMonitoringTool()

# --- AGENTES (usando RouteLLM direto) ---
data_collector_agent = Agent(
    role='Coletor de M√©tricas da API',
    goal='Coletar dados vitais dos endpoints de sa√∫de.',
    backstory='Rob√¥ especializado em requisi√ß√µes HTTP para m√©tricas.',
    tools=[api_tool],
    verbose=True,
    llm=route_llm,  # üîë usando fun√ß√£o wrapper direta
    allow_delegation=False
)

data_analyzer_agent = Agent(
    role='Analista de Sa√∫de da Aplica√ß√£o',
    goal='Interpretar os dados coletados e detectar anomalias.',
    backstory='Especialista em identifica√ß√£o de falhas em sistemas.',
    verbose=True,
    llm=route_llm,  # üîë usando fun√ß√£o wrapper direta
    allow_delegation=False
)

notification_agent = Agent(
    role='Gerador de Alertas',
    goal='Transformar os insights t√©cnicos em alertas claros e objetivos.',
    backstory='Profissional em comunica√ß√£o t√©cnica para times de dev.',
    verbose=True,
    llm=route_llm,  # üîë usando fun√ß√£o wrapper direta
    allow_delegation=False
)

# --- TAREFAS ---
collect_data_task = Task(
    description=(
        'Use a ferramenta "API Monitoring Tool" para buscar dados nos endpoints: '
        '`/actuator/health` e `/actuator/metrics/jvm.memory.used`. '
        'Combine as respostas em JSON unificado com chaves claras.'
    ),
    expected_output='JSON com dados brutos: {"health": {...}, "jvmMemoryUsed": {...}}',
    agent=data_collector_agent
)

analyze_data_task = Task(
    description=(
        'Analise os dados coletados: '
        '- health.status deve ser "UP". '
        '- Se mem√≥ria usada (em bytes) > 700MB (734003200 bytes) ‚Üí levantar alerta. '
        'Produza um resumo curto e objetivo em portugu√™s com conclus√µes e m√©tricas.'
    ),
    expected_output='Relat√≥rio com status e uso de mem√≥ria, incluindo se h√° alerta.',
    agent=data_analyzer_agent,
    context=[collect_data_task]
)

notify_task = Task(
    description=(
        'Com base na an√°lise, redija a mensagem final de notifica√ß√£o. '
        'Se tudo ok ‚Üí mensagem positiva com status e uso de mem√≥ria. '
        'Se falha/alerta ‚Üí mensagem de alerta clara, concisa e acion√°vel.'
    ),
    expected_output='Mensagem final para equipe (1-3 par√°grafos curtos).',
    agent=notification_agent,
    context=[analyze_data_task]
)

# --- CREW ---
api_monitoring_crew = Crew(
    agents=[data_collector_agent, data_analyzer_agent, notification_agent],
    tasks=[collect_data_task, analyze_data_task, notify_task],
    process=Process.sequential,
    verbose=True
)

if __name__ == "__main__":
    try:
        print("üöÄ Iniciando monitoramento da API...")

        # Teste r√°pido da conex√£o com RouteLLM
        try:
            test_response = route_llm("teste de conex√£o")
            print("‚úÖ Conex√£o com RouteLLM OK")
        except Exception as e:
            print(f"‚ö†Ô∏è Aviso: Problema na conex√£o RouteLLM: {e}")

        result = api_monitoring_crew.kickoff()

        log_entry = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "result": str(result)
        }
        persist_data(log_entry)

        print("\n\n########################")
        print("## Resultado Final do Monitoramento:")
        print("########################\n")
        print(result)
        print("üìÅ Salvo em monitoring_logs.json")

    except Exception as e:
        print("‚ùå Erro durante execu√ß√£o:", str(e))
        persist_data({
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "error": str(e)
        })