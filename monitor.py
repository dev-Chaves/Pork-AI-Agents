import os
import json
import time
import statistics
from collections import Counter, defaultdict
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any
import requests
import schedule
from dotenv import load_dotenv
from openai import OpenAI

from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool

# ====
# Carrega vari√°veis de ambiente
# ====
load_dotenv()

# Vari√°veis essenciais
required_vars = ["OPENAI_API_KEY", "API_BASE_URL", "MONITORING_API_KEY"]
missing = [k for k in required_vars if not os.getenv(k)]
if missing:
    raise RuntimeError(f"Vari√°veis ausentes no .env: {', '.join(missing)}")

# Configura√ß√µes do Telegram (opcionais)
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

# Vari√°vel para controlar updates j√° processados
last_update_id = 0

# Thresholds com defaults razo√°veis
MEMORY_ALERT_MB = int(os.getenv("MEMORY_ALERT_MB", "700"))
CPU_ALERT_PCT = float(os.getenv("CPU_ALERT_PCT", "85.0"))
ERROR_RATE_SLO_PCT = float(os.getenv("ERROR_RATE_SLO_PCT", "1.0"))
LATENCY_P95_SLO_MS = int(os.getenv("LATENCY_P95_SLO_MS", "800"))
LATENCY_AVG_SLO_MS = int(os.getenv("LATENCY_AVG_SLO_MS", "500"))

# ====
# Configura√ß√£o RouteLLM (Abacus.AI)
# ====
client = OpenAI(
    base_url="https://routellm.abacus.ai/v1",
    api_key=os.getenv("OPENAI_API_KEY"),
)

class RouteLLMWrapper:
    """Wrapper para usar RouteLLM com CrewAI."""
    def __init__(self, model="gpt-4o-mini", temperature=0):
        self.model = model
        self.temperature = temperature

    def __call__(self, messages, **kwargs):
        return self._generate(messages, **kwargs)

    def invoke(self, messages, **kwargs):
        return self._generate(messages, **kwargs)

    def _generate(self, messages, **kwargs):
        if isinstance(messages, str):
            messages = [{"role": "user", "content": messages}]
        try:
            response = client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=kwargs.get("temperature", self.temperature),
                max_tokens=kwargs.get("max_tokens", 2500),
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Erro na chamada LLM: {str(e)}"

llm = RouteLLMWrapper(model="gpt-4o-mini", temperature=0)

# ====
# Persist√™ncia de logs e an√°lises
# ====
LOG_FILE = "monitoring_logs.json"
ANALYTICS_FILE = "api_analytics.json"
EXCEPTIONS_FILE = "exceptions_report.json"

def persist_data(entry: dict, filename: str = LOG_FILE):
    """Persiste dados em arquivo JSON."""
    try:
        if not os.path.exists(filename):
            with open(filename, "w", encoding="utf-8") as f:
                json.dump([], f)
        with open(filename, "r+", encoding="utf-8") as f:
            data = json.load(f)
            data.append(entry)
            # Mant√©m apenas √∫ltimos 1000 registros
            if len(data) > 1000:
                data = data[-1000:]
            f.seek(0)
            json.dump(data, f, indent=2, ensure_ascii=False)
            f.truncate()
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao salvar em {filename}: {e}")

def load_data(filename: str) -> List[Dict]:
    """Carrega dados de arquivo JSON."""
    try:
        if os.path.exists(filename):
            with open(filename, "r", encoding="utf-8") as f:
                return json.load(f)
        return []
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar {filename}: {e}")
        return []

# ====
# An√°lise de Exce√ß√µes e Estat√≠sticas
# ====
class ExceptionAnalyzer:
    """Analisa exce√ß√µes e gera estat√≠sticas detalhadas."""
    
    @staticmethod
    def analyze_http_traces(traces_data: Any) -> Dict:
        """Analisa traces HTTP para extrair exce√ß√µes e estat√≠sticas."""
        analysis = {
            "total_requests": 0,
            "status_codes": Counter(),
            "exceptions": [],
            "exception_types": Counter(),
            "endpoints": Counter(),
            "methods": Counter(),
            "response_times": [],
            "errors_by_endpoint": defaultdict(list),
            "time_range": {"start": None, "end": None}
        }
        
        try:
            # Suporta diferentes formatos do Actuator
            exchanges = []
            if isinstance(traces_data, dict):
                exchanges = traces_data.get("exchanges", []) or traces_data.get("traces", [])
            elif isinstance(traces_data, list):
                exchanges = traces_data
            
            for exchange in exchanges:
                analysis["total_requests"] += 1
                
                # Extrai informa√ß√µes da requisi√ß√£o
                request = exchange.get("request", {})
                response = exchange.get("response", {})
                
                method = request.get("method", "UNKNOWN")
                uri = request.get("uri", "UNKNOWN")
                status = response.get("status", 0)
                timestamp = exchange.get("timestamp")
                
                # Tempo de resposta (se dispon√≠vel)
                time_taken = exchange.get("timeTaken") or exchange.get("duration")
                if time_taken:
                    analysis["response_times"].append(time_taken)
                
                # Contadores
                analysis["status_codes"][status] += 1
                analysis["endpoints"][uri] += 1
                analysis["methods"][method] += 1
                
                # Detecta exce√ß√µes (qualquer status >= 400)
                if status >= 400:
                    exception_info = {
                        "timestamp": timestamp,
                        "method": method,
                        "endpoint": uri,
                        "status": status,
                        "time_taken_ms": time_taken,
                        "error_type": ExceptionAnalyzer._classify_error(status),
                        "headers": response.get("headers", {}),
                        "session_id": exchange.get("sessionId")
                    }
                    
                    analysis["exceptions"].append(exception_info)
                    analysis["exception_types"][exception_info["error_type"]] += 1
                    analysis["errors_by_endpoint"][uri].append(exception_info)
                
                # Atualiza range de tempo
                if timestamp:
                    if not analysis["time_range"]["start"]:
                        analysis["time_range"]["start"] = timestamp
                    analysis["time_range"]["end"] = timestamp
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao analisar traces: {e}")
        
        return analysis
    
    @staticmethod
    def _classify_error(status: int) -> str:
        """Classifica tipo de erro baseado no status HTTP."""
        if status == 400:
            return "BAD_REQUEST"
        elif status == 401:
            return "UNAUTHORIZED"
        elif status == 403:
            return "FORBIDDEN"
        elif status == 404:
            return "NOT_FOUND"
        elif status == 408:
            return "REQUEST_TIMEOUT"
        elif status == 429:
            return "RATE_LIMIT"
        elif status == 500:
            return "INTERNAL_SERVER_ERROR"
        elif status == 502:
            return "BAD_GATEWAY"
        elif status == 503:
            return "SERVICE_UNAVAILABLE"
        elif status == 504:
            return "GATEWAY_TIMEOUT"
        elif 400 <= status < 500:
            return "CLIENT_ERROR"
        elif 500 <= status < 600:
            return "SERVER_ERROR"
        else:
            return "UNKNOWN_ERROR"
    
    @staticmethod
    def calculate_statistics(analysis: Dict) -> Dict:
        """Calcula estat√≠sticas detalhadas."""
        stats = {
            "total_requests": analysis["total_requests"],
            "total_errors": len(analysis["exceptions"]),
            "error_rate_pct": 0.0,
            "status_distribution": dict(analysis["status_codes"]),
            "top_endpoints": analysis["endpoints"].most_common(10),
            "top_exception_types": dict(analysis["exception_types"]),
            "methods_distribution": dict(analysis["methods"]),
            "response_time_stats": {},
            "most_problematic_endpoints": []
        }
        
        # Taxa de erro
        if stats["total_requests"] > 0:
            stats["error_rate_pct"] = (stats["total_errors"] / stats["total_requests"]) * 100
        
        # Estat√≠sticas de tempo de resposta
        if analysis["response_times"]:
            times = sorted(analysis["response_times"])
            stats["response_time_stats"] = {
                "min_ms": min(times),
                "max_ms": max(times),
                "avg_ms": statistics.mean(times),
                "median_ms": statistics.median(times),
                "p95_ms": times[int(len(times) * 0.95)] if len(times) > 0 else 0,
                "p99_ms": times[int(len(times) * 0.99)] if len(times) > 0 else 0,
            }
        
        # Endpoints mais problem√°ticos
        endpoint_errors = [
            {
                "endpoint": endpoint,
                "error_count": len(errors),
                "error_types": Counter([e["error_type"] for e in errors])
            }
            for endpoint, errors in analysis["errors_by_endpoint"].items()
        ]
        endpoint_errors.sort(key=lambda x: x["error_count"], reverse=True)
        stats["most_problematic_endpoints"] = endpoint_errors[:10]
        
        return stats

# ====
# Gerador de Relat√≥rios
# ====
class ReportGenerator:
    """Gera relat√≥rios detalhados de monitoramento."""
    
    @staticmethod
    def generate_comprehensive_report(analysis: Dict, stats: Dict, metrics: Dict) -> str:
        """Gera relat√≥rio completo em formato markdown."""
        report = []
        report.append("# üìä RELAT√ìRIO DE MONITORAMENTO DA API\n")
        report.append(f"**Data/Hora:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
        
        # Per√≠odo analisado
        if analysis["time_range"]["start"]:
            report.append(f"**Per√≠odo:** {analysis['time_range']['start']} at√© {analysis['time_range']['end']}\n")
        
        report.append("\n---\n")
        
        # Resumo Executivo
        report.append("## üéØ RESUMO EXECUTIVO\n")
        report.append(f"- **Total de Requisi√ß√µes:** {stats['total_requests']:,}")
        report.append(f"- **Total de Erros:** {stats['total_errors']:,}")
        report.append(f"- **Taxa de Erro:** {stats['error_rate_pct']:.2f}%")
        
        if stats["response_time_stats"]:
            rt = stats["response_time_stats"]
            report.append(f"- **Tempo M√©dio de Resposta:** {rt['avg_ms']:.0f}ms")
            report.append(f"- **P95 Lat√™ncia:** {rt['p95_ms']:.0f}ms")
            report.append(f"- **P99 Lat√™ncia:** {rt['p99_ms']:.0f}ms")
        
        report.append("\n---\n")
        
        # Distribui√ß√£o de Status HTTP
        report.append("## üìà DISTRIBUI√á√ÉO DE STATUS HTTP\n")
        for status, count in sorted(stats["status_distribution"].items()):
            pct = (count / stats["total_requests"]) * 100 if stats["total_requests"] > 0 else 0
            emoji = "‚úÖ" if status < 400 else "‚ö†Ô∏è" if status < 500 else "‚ùå"
            report.append(f"{emoji} **{status}:** {count:,} ({pct:.1f}%)")
        
        report.append("\n---\n")
        
        # Tipos de Exce√ß√µes
        if stats["top_exception_types"]:
            report.append("## üö® TIPOS DE EXCE√á√ïES MAIS FREQUENTES\n")
            for exc_type, count in sorted(stats["top_exception_types"].items(), 
                                         key=lambda x: x[1], reverse=True):
                pct = (count / stats["total_errors"]) * 100 if stats["total_errors"] > 0 else 0
                report.append(f"- **{exc_type}:** {count:,} ({pct:.1f}%)")
        
        report.append("\n---\n")
        
        # Endpoints Mais Usados
        report.append("## üî• TOP 10 ENDPOINTS MAIS REQUISITADOS\n")
        for endpoint, count in stats["top_endpoints"]:
            pct = (count / stats["total_requests"]) * 100 if stats["total_requests"] > 0 else 0
            report.append(f"- `{endpoint}`: {count:,} ({pct:.1f}%)")
        
        report.append("\n---\n")
        
        # Endpoints Problem√°ticos
        if stats["most_problematic_endpoints"]:
            report.append("## ‚ö†Ô∏è ENDPOINTS MAIS PROBLEM√ÅTICOS\n")
            for item in stats["most_problematic_endpoints"][:5]:
                report.append(f"\n### `{item['endpoint']}`")
                report.append(f"- **Total de Erros:** {item['error_count']}")
                report.append("- **Tipos de Erro:**")
                for err_type, count in item["error_types"].items():
                    report.append(f"  - {err_type}: {count}")
        
        report.append("\n---\n")
        
        # M√©tricas de Sistema
        report.append("## üíª M√âTRICAS DE SISTEMA\n")
        if metrics.get("memory_used_mb"):
            report.append(f"- **Mem√≥ria Usada:** {metrics['memory_used_mb']}MB / {metrics.get('memory_max_mb', 'N/A')}MB ({metrics.get('memory_used_pct', 0):.1f}%)")
        if metrics.get("cpu_usage_pct"):
            report.append(f"- **CPU:** {metrics['cpu_usage_pct']:.1f}%")
        
        report.append("\n---\n")
        
        # Tempos de Resposta Detalhados
        if stats["response_time_stats"]:
            report.append("## ‚ö° AN√ÅLISE DE PERFORMANCE\n")
            rt = stats["response_time_stats"]
            report.append(f"- **M√≠nimo:** {rt['min_ms']:.0f}ms")
            report.append(f"- **M√°ximo:** {rt['max_ms']:.0f}ms")
            report.append(f"- **M√©dia:** {rt['avg_ms']:.0f}ms")
            report.append(f"- **Mediana:** {rt['median_ms']:.0f}ms")
            report.append(f"- **P95:** {rt['p95_ms']:.0f}ms")
            report.append(f"- **P99:** {rt['p99_ms']:.0f}ms")
            
            # Alertas de performance
            if rt['avg_ms'] > LATENCY_AVG_SLO_MS:
                report.append(f"\n‚ö†Ô∏è **ALERTA:** Tempo m√©dio ({rt['avg_ms']:.0f}ms) acima do SLO ({LATENCY_AVG_SLO_MS}ms)")
            if rt['p95_ms'] > LATENCY_P95_SLO_MS:
                report.append(f"\n‚ö†Ô∏è **ALERTA:** P95 ({rt['p95_ms']:.0f}ms) acima do SLO ({LATENCY_P95_SLO_MS}ms)")
        
        report.append("\n---\n")
        
        # Distribui√ß√£o de M√©todos HTTP
        report.append("## üîÑ DISTRIBUI√á√ÉO DE M√âTODOS HTTP\n")
        for method, count in sorted(stats["methods_distribution"].items(), 
                                    key=lambda x: x[1], reverse=True):
            pct = (count / stats["total_requests"]) * 100 if stats["total_requests"] > 0 else 0
            report.append(f"- **{method}:** {count:,} ({pct:.1f}%)")
        
        return "\n".join(report)

# ====
# Notifica√ß√£o via Telegram
# ====
def send_telegram_notification(message: str, parse_mode: str = None):
    """Envia notifica√ß√£o via Telegram."""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("‚ö†Ô∏è Telegram n√£o configurado. Pulando notifica√ß√£o.")
        return False
    
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        
        # Divide mensagens longas
        max_length = 4000
        if len(message) > max_length:
            parts = [message[i:i+max_length] for i in range(0, len(message), max_length)]
            for part in parts:
                data = {
                    "chat_id": TELEGRAM_CHAT_ID,
                    "text": part,
                    "disable_web_page_preview": True
                }
                if parse_mode:
                    data["parse_mode"] = parse_mode
                
                response = requests.post(url, json=data, timeout=10)
                response.raise_for_status()
                time.sleep(1)  # Evita rate limit
        else:
            data = {
                "chat_id": TELEGRAM_CHAT_ID,
                "text": message,
                "disable_web_page_preview": True
            }
            if parse_mode:
                data["parse_mode"] = parse_mode
            
            response = requests.post(url, json=data, timeout=10)
            response.raise_for_status()
        
        print("‚úÖ Notifica√ß√£o enviada via Telegram")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao enviar Telegram: {e}")
        return False

# ====
# Escuta de comandos do Telegram
# ====
def listen_for_commands():
    """Faz polling no Telegram para ouvir comandos."""
    global last_update_id
    
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        return

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/getUpdates"
    params = {"offset": last_update_id + 1, "timeout": 1}
    
    try:
        response = requests.get(url, params=params, timeout=5)
        data = response.json()

        if "result" in data and data["result"]:
            for update in data["result"]:
                last_update_id = update["update_id"]
                
                if "message" in update:
                    chat_id = update["message"]["chat"]["id"]
                    text = update["message"].get("text", "").strip()
                    username = update["message"]["from"].get("username", "Usu√°rio")

                    if str(chat_id) != str(TELEGRAM_CHAT_ID):
                        continue

                    print(f"üì± Comando recebido de @{username}: {text}")

                    if text == "/status":
                        send_telegram_notification("‚úÖ Bot est√° rodando normalmente!")
                    
                    elif text == "/run":
                        send_telegram_notification("üöÄ Executando monitoramento sob comando...")
                        run_monitoring()
                    
                    elif text == "/report":
                        send_telegram_notification("üìä Gerando relat√≥rio completo...")
                        generate_and_send_report()
                    
                    elif text == "/exceptions":
                        send_telegram_notification("üö® Gerando relat√≥rio de exce√ß√µes...")
                        generate_exceptions_report()
                    
                    elif text == "/stats":
                        send_telegram_notification("üìà Gerando estat√≠sticas...")
                        generate_stats_report()
                    
                    elif text == "/help":
                        help_msg = (
                            "üìñ Comandos dispon√≠veis:\n\n"
                            "/status - Ver se o bot est√° online\n"
                            "/run - Executar monitoramento agora\n"
                            "/report - Relat√≥rio completo\n"
                            "/exceptions - Relat√≥rio de exce√ß√µes\n"
                            "/stats - Estat√≠sticas detalhadas\n"
                            "/logs - Ver √∫ltimos logs\n"
                            "/config - Ver configura√ß√µes\n"
                            "/help - Mostrar esta ajuda"
                        )
                        send_telegram_notification(help_msg)
                    
                    elif text == "/logs":
                        logs = load_data(LOG_FILE)
                        if logs:
                            last_log = logs[-1]
                            timestamp = last_log.get("timestamp", "N/A")
                            log_msg = f"üìã √öltimo log:\n\n‚è∞ {timestamp}\n\n"
                            if "error" in last_log:
                                log_msg += f"‚ùå Erro: {last_log['error']}"
                            else:
                                log_msg += "‚úÖ Execu√ß√£o bem-sucedida"
                            send_telegram_notification(log_msg)
                        else:
                            send_telegram_notification("üìã Nenhum log encontrado.")
                    
                    elif text == "/config":
                        config_msg = (
                            f"‚öôÔ∏è Configura√ß√µes atuais:\n\n"
                            f"‚Ä¢ Mem√≥ria Alert: {MEMORY_ALERT_MB}MB\n"
                            f"‚Ä¢ CPU Alert: {CPU_ALERT_PCT}%\n"
                            f"‚Ä¢ Error Rate SLO: {ERROR_RATE_SLO_PCT}%\n"
                            f"‚Ä¢ Latency AVG SLO: {LATENCY_AVG_SLO_MS}ms\n"
                            f"‚Ä¢ Latency P95 SLO: {LATENCY_P95_SLO_MS}ms\n"
                            f"‚Ä¢ Telegram: {'‚úÖ Configurado' if TELEGRAM_BOT_TOKEN else '‚ùå N√£o configurado'}"
                        )
                        send_telegram_notification(config_msg)
                    
                    else:
                        send_telegram_notification(
                            f"‚ùì Comando n√£o reconhecido: {text}\n\n"
                            "Digite /help para ver os comandos dispon√≠veis."
                        )

    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao ouvir comandos: {e}")

# ====
# Ferramenta de coleta com retry/backoff
# ====
class ApiMonitoringTool(BaseTool):
    """Ferramenta para requisi√ß√µes aos endpoints de monitoramento."""
    name: str = "API Monitoring Tool"
    description: str = "Faz GET em endpoints de monitoramento e retorna o texto da resposta."

    def _run(self, endpoint: str) -> str:
        return self._get_with_retry(endpoint)

    def _get_with_retry(self, endpoint: str, retries: int = 3, timeout: int = 15) -> str:
        api_base_url = os.getenv("API_BASE_URL")
        api_key = os.getenv("MONITORING_API_KEY")

        if not api_base_url or not api_key:
            return "Erro: Vari√°veis API_BASE_URL ou MONITORING_API_KEY n√£o definidas."

        headers = {
            "Content-Type": "application/json",
            "X-API-KEY": api_key
        }

        url = f"{api_base_url.rstrip('/')}/{endpoint.lstrip('/')}"
        last_error = None
        for attempt in range(retries):
            try:
                response = requests.get(url, headers=headers, timeout=timeout)
                response.raise_for_status()
                try:
                    return json.dumps(response.json(), ensure_ascii=False)
                except Exception:
                    return response.text
            except requests.exceptions.RequestException as e:
                last_error = e
                sleep_secs = 2 ** attempt
                time.sleep(sleep_secs)
        return f"Erro ao acessar {endpoint}: {last_error}"

api_tool = ApiMonitoringTool()

# ====
# Agentes Aprimorados
# ====

# Agente 1: Coletor Avan√ßado
collector_prompt = """
Voc√™ √© um coletor avan√ßado de m√©tricas de uma aplica√ß√£o Spring Boot (Actuator).
Use a ferramenta "API Monitoring Tool" para buscar TODOS os dados dos seguintes endpoints:

ENDPOINTS OBRIGAT√ìRIOS:
- /actuator/health
- /actuator/info
- /actuator/metrics/jvm.memory.used
- /actuator/metrics/jvm.memory.max
- /actuator/metrics/process.cpu.usage
- /actuator/metrics/http.server.requests

ENDPOINTS DE TRACES (tente ambos, use o que funcionar):
- /actuator/httptrace
- /actuator/httpexchanges

ENDPOINTS ADICIONAIS (se dispon√≠veis):
- /actuator/loggers
- /actuator/metrics/jvm.threads.live
- /actuator/metrics/jvm.gc.pause
- /actuator/metrics/system.cpu.usage

Retorne EXATAMENTE um JSON √∫nico com TODOS os dados coletados:
{
  "health": <obj ou null>,
  "info": <obj ou null>,
  "httptrace": <obj ou null>,
  "httpexchanges": <obj ou null>,
  "loggers": <obj ou null>,
  "metrics": {
    "jvm.memory.used": <obj ou null>,
    "jvm.memory.max": <obj ou null>,
    "process.cpu.usage": <obj ou null>,
    "http.server.requests": <obj ou null>,
    "jvm.threads.live": <obj ou null>,
    "jvm.gc.pause": <obj ou null>,
    "system.cpu.usage": <obj ou null>
  }
}

IMPORTANTE: N√£o adicione texto fora do JSON. Se um endpoint falhar, coloque null.
"""

data_collector_agent = Agent(
    role='Coletor Avan√ßado de M√©tricas',
    goal='Coletar TODOS os dados dispon√≠veis dos endpoints de monitoramento.',
    backstory='Especialista em coleta exaustiva de m√©tricas e traces de aplica√ß√µes.',
    tools=[api_tool],
    verbose=True,
    llm=llm,
    allow_delegation=False
)

collect_data_task = Task(
    description=collector_prompt,
    expected_output='JSON completo com todos os dados coletados',
    agent=data_collector_agent
)

# Agente 2: Analisador de Exce√ß√µes
exception_analyzer_prompt = f"""
Voc√™ √© um especialista em an√°lise de exce√ß√µes e erros de APIs.
Receber√° um JSON com dados do Actuator e deve fazer uma an√°lise PROFUNDA de TODAS as exce√ß√µes.

AN√ÅLISE OBRIGAT√ìRIA:
1. TODAS as exce√ß√µes (n√£o s√≥ 500, mas 400, 401, 403, 404, 408, 429, 502, 503, 504, etc)
2. Frequ√™ncia de cada tipo de exce√ß√£o
3. Endpoints que mais geram erros
4. Padr√µes temporais (se houver timestamps)
5. Correla√ß√£o entre tipos de erro e endpoints
6. Taxa de erro geral e por endpoint
7. Classifica√ß√£o de severidade

M√âTRICAS DE SISTEMA:
- Converter mem√≥ria para MB e percentual
- CPU em percentual
- Threads ativas
- GC pause time (se dispon√≠vel)

THRESHOLDS:
- MEMORY_ALERT_MB = {MEMORY_ALERT_MB}
- CPU_ALERT_PCT = {CPU_ALERT_PCT}
- ERROR_RATE_SLO_PCT = {ERROR_RATE_SLO_PCT}
- LATENCY_AVG_SLO_MS = {LATENCY_AVG_SLO_MS}
- LATENCY_P95_SLO_MS = {LATENCY_P95_SLO_MS}

Retorne EXATAMENTE este JSON:
{{
  "summary": "resumo executivo",
  "severity": "INFO|WARN|ALERT|CRITICAL",
  "exceptions_analysis": {{
    "total_exceptions": <int>,
    "exception_types": {{"tipo": count}},
    "exceptions_by_status": {{"status": count}},
    "most_problematic_endpoints": [
      {{"endpoint": "uri", "error_count": <int>, "error_types": {{}}}
    ],
    "error_rate_pct": <float>,
    "client_errors_4xx": <int>,
    "server_errors_5xx": <int>
  }},
  "performance_analysis": {{
    "total_requests": <int>,
    "avg_response_time_ms": <float ou null>,
    "p95_response_time_ms": <float ou null>,
    "p99_response_time_ms": <float ou null>,
    "slowest_endpoints": []
  }},
  "system_metrics": {{
    "memory_used_mb": <int ou null>,
    "memory_max_mb": <int ou null>,
    "memory_used_pct": <float ou null>,
    "cpu_usage_pct": <float ou null>,
    "threads_live": <int ou null>
  }},
  "findings": [
    {{
      "area": "EXCEPTIONS|PERFORMANCE|MEMORY|CPU",
      "status": "OK|WARN|ALERT|CRITICAL",
      "metric": "nome",
      "value": "valor",
      "threshold": "limite",
      "details": "explica√ß√£o"
    }}
  ],
  "actions": ["a√ß√£o 1", "a√ß√£o 2"]
}}
"""

exception_analyzer_agent = Agent(
    role='Analista de Exce√ß√µes e Performance',
    goal='Analisar TODAS as exce√ß√µes, erros e m√©tricas de performance em profundidade.',
    backstory='Engenheiro de confiabilidade especializado em an√°lise de falhas e otimiza√ß√£o.',
    verbose=True,
    llm=llm,
    allow_delegation=False
)

analyze_exceptions_task = Task(
    description=exception_analyzer_prompt,
    expected_output='JSON estruturado com an√°lise completa de exce√ß√µes e performance',
    agent=exception_analyzer_agent,
    context=[collect_data_task]
)

# Agente 3: Gerador de Relat√≥rio
report_generator_prompt = """
Voc√™ √© um gerador de relat√≥rios executivos para equipes de engenharia.
Receber√° uma an√°lise completa e deve gerar um relat√≥rio CONCISO e ACION√ÅVEL.

ESTRUTURA DO RELAT√ìRIO:
1. Status Geral (emoji + resumo de 1 linha)
2. M√©tricas Principais (3-5 n√∫meros-chave)
3. Problemas Cr√≠ticos (se houver)
4. Top 3 Tipos de Exce√ß√µes
5. Top 3 Endpoints Problem√°ticos
6. A√ß√µes Recomendadas (m√°ximo 5, priorizadas)

REGRAS:
- M√°ximo 15 linhas
- Use emojis para facilitar leitura
- N√∫meros formatados (ex: 1,234 ou 45.2%)
- Priorize informa√ß√µes acion√°veis
- Destaque alertas cr√≠ticos

Formato de sa√≠da: texto limpo, sem markdown pesado.
"""

report_generator_agent = Agent(
    role='Gerador de Relat√≥rios Executivos',
    goal='Criar relat√≥rios concisos e acion√°veis para a equipe.',
    backstory='Especialista em comunica√ß√£o t√©cnica e prioriza√ß√£o de problemas.',
    verbose=True,
    llm=llm,
    allow_delegation=False
)

generate_report_task = Task(
    description=report_generator_prompt,
    expected_output='Relat√≥rio executivo conciso e acion√°vel',
    agent=report_generator_agent,
    context=[analyze_exceptions_task]
)

# ====
# Orquestra√ß√£o
# ====
api_monitoring_crew = Crew(
    agents=[data_collector_agent, exception_analyzer_agent, report_generator_agent],
    tasks=[collect_data_task, analyze_exceptions_task, generate_report_task],
    process=Process.sequential,
    verbose=True
)

# ====
# Fun√ß√µes de Relat√≥rio
# ====
def generate_and_send_report():
    """Gera e envia relat√≥rio completo."""
    try:
        analytics = load_data(ANALYTICS_FILE)
        if not analytics:
            send_telegram_notification("‚ö†Ô∏è Nenhum dado de an√°lise dispon√≠vel ainda.")
            return
        
        latest = analytics[-1]
        analysis = latest.get("analysis", {})
        stats = latest.get("statistics", {})
        metrics = latest.get("system_metrics", {})
        
        report = ReportGenerator.generate_comprehensive_report(analysis, stats, metrics)
        
        # Salva relat√≥rio em arquivo
        report_file = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report)
        
        send_telegram_notification(f"üìä Relat√≥rio completo gerado: {report_file}\n\n{report[:3000]}...")
        print(f"‚úÖ Relat√≥rio salvo em {report_file}")
        
    except Exception as e:
        send_telegram_notification(f"‚ùå Erro ao gerar relat√≥rio: {e}")

def generate_exceptions_report():
    """Gera relat√≥rio focado em exce√ß√µes."""
    try:
        exceptions_data = load_data(EXCEPTIONS_FILE)
        if not exceptions_data:
            send_telegram_notification("‚ö†Ô∏è Nenhum dado de exce√ß√µes dispon√≠vel.")
            return
        
        latest = exceptions_data[-1]
        
        report = []
        report.append("üö® RELAT√ìRIO DE EXCE√á√ïES\n")
        report.append(f"Total de Exce√ß√µes: {latest.get('total_exceptions', 0)}")
        report.append(f"Taxa de Erro: {latest.get('error_rate_pct', 0):.2f}%\n")
        
        report.append("Top Tipos de Exce√ß√£o:")
        for exc_type, count in list(latest.get('exception_types', {}).items())[:5]:
            report.append(f"  ‚Ä¢ {exc_type}: {count}")
        
        report.append("\nEndpoints Mais Problem√°ticos:")
        for ep in latest.get('most_problematic_endpoints', [])[:5]:
            report.append(f"  ‚Ä¢ {ep['endpoint']}: {ep['error_count']} erros")
        
        send_telegram_notification("\n".join(report))
        
    except Exception as e:
        send_telegram_notification(f"‚ùå Erro ao gerar relat√≥rio de exce√ß√µes: {e}")

def generate_stats_report():
    """Gera relat√≥rio de estat√≠sticas."""
    try:
        analytics = load_data(ANALYTICS_FILE)
        if not analytics:
            send_telegram_notification("‚ö†Ô∏è Nenhum dado estat√≠stico dispon√≠vel.")
            return
        
        latest = analytics[-1]
        stats = latest.get("statistics", {})
        
        report = []
        report.append("üìà ESTAT√çSTICAS DA API\n")
        report.append(f"Total de Requisi√ß√µes: {stats.get('total_requests', 0):,}")
        report.append(f"Total de Erros: {stats.get('total_errors', 0):,}")
        report.append(f"Taxa de Erro: {stats.get('error_rate_pct', 0):.2f}%\n")
        
        if stats.get("response_time_stats"):
            rt = stats["response_time_stats"]
            report.append("Tempos de Resposta:")
            report.append(f"  ‚Ä¢ M√©dia: {rt.get('avg_ms', 0):.0f}ms")
            report.append(f"  ‚Ä¢ P95: {rt.get('p95_ms', 0):.0f}ms")
            report.append(f"  ‚Ä¢ P99: {rt.get('p99_ms', 0):.0f}ms\n")
        
        report.append("Top Endpoints:")
        for endpoint, count in stats.get("top_endpoints", [])[:5]:
            report.append(f"  ‚Ä¢ {endpoint}: {count:,}")
        
        send_telegram_notification("\n".join(report))
        
    except Exception as e:
        send_telegram_notification(f"‚ùå Erro ao gerar estat√≠sticas: {e}")

# ====
# Fun√ß√£o principal de monitoramento
# ====
def run_monitoring():
    """Executa o monitoramento completo."""
    start_time = time.time()
    
    try:
        print("üöÄ Iniciando monitoramento avan√ßado da API...")

        # Executa o monitoramento
        result = api_monitoring_crew.kickoff()
        
        response_time = time.time() - start_time
        
        # Extrai dados de an√°lise
        analysis_data = None
        collected_data = None
        
        try:
            if hasattr(result, 'tasks_output') and len(result.tasks_output) >= 2:
                # Dados coletados
                collected_output = str(result.tasks_output[0])
                collected_data = json.loads(collected_output)
                
                # An√°lise
                analysis_output = str(result.tasks_output[1])
                analysis_data = json.loads(analysis_output)
                
                # Processa traces para an√°lise detalhada
                traces = collected_data.get("httptrace") or collected_data.get("httpexchanges")
                if traces:
                    analyzer = ExceptionAnalyzer()
                    trace_analysis = analyzer.analyze_http_traces(traces)
                    statistics_data = analyzer.calculate_statistics(trace_analysis)
                    
                    # Salva an√°lise detalhada
                    analytics_entry = {
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "analysis": trace_analysis,
                        "statistics": statistics_data,
                        "system_metrics": analysis_data.get("system_metrics", {})
                    }
                    persist_data(analytics_entry, ANALYTICS_FILE)
                    
                    # Salva exce√ß√µes
                    exceptions_entry = {
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "total_exceptions": len(trace_analysis["exceptions"]),
                        "exception_types": dict(trace_analysis["exception_types"]),
                        "error_rate_pct": statistics_data.get("error_rate_pct", 0),
                        "most_problematic_endpoints": statistics_data.get("most_problematic_endpoints", [])
                    }
                    persist_data(exceptions_entry, EXCEPTIONS_FILE)
                    
                    print(f"‚úÖ An√°lise detalhada salva:")
                    print(f"   - Total de requisi√ß√µes: {statistics_data['total_requests']}")
                    print(f"   - Total de exce√ß√µes: {statistics_data['total_errors']}")
                    print(f"   - Taxa de erro: {statistics_data['error_rate_pct']:.2f}%")
                    
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao processar an√°lise detalhada: {e}")

        # Salva log
        log_entry = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "response_time_seconds": round(response_time, 2),
            "result": str(result),
            "analysis_data": analysis_data
        }
        persist_data(log_entry, LOG_FILE)

        print(f"\n####")
        print(f"## Resultado Final do Monitoramento:")
        print(f"## Tempo de resposta: {response_time:.2f}s")
        print(f"####\n")
        print(result)

        # Envia notifica√ß√£o
        notification_message = f"‚ö° Tempo: {response_time:.1f}s\n\n{str(result)}"
        send_telegram_notification(notification_message)

    except Exception as e:
        error_msg = f"‚ùå Erro durante execu√ß√£o: {str(e)}"
        print(error_msg)
        
        persist_data({
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "error": str(e),
            "response_time_seconds": round(time.time() - start_time, 2)
        }, LOG_FILE)
        
        send_telegram_notification(f"üö® ERRO no Monitor\n\n{error_msg}")

# ====
# Agendamento e execu√ß√£o
# ====
if __name__ == "__main__":
    print("ü§ñ Monitor Avan√ßado de API iniciado!")
    print("üìÖ Agendado para rodar diariamente √†s 12:00")
    print("üîç Monitoramento de TODAS as exce√ß√µes ativado")
    
    if TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID:
        print("‚úÖ Telegram configurado")
        print("üí¨ Comandos: /help, /run, /report, /exceptions, /stats")
    else:
        print("‚ö†Ô∏è Telegram n√£o configurado")
    
    # Agenda execu√ß√£o
    schedule.every().day.at("12:00").do(run_monitoring)
    
    # Execu√ß√£o inicial
    print("\nüß™ Executando teste inicial...")
    run_monitoring()
    
    print(f"\n‚è∞ Aguardando pr√≥xima execu√ß√£o...")
    print("üí° Pressione Ctrl+C para parar")
    
    # Loop principal
    try:
        while True:
            schedule.run_pending()
            listen_for_commands()
            time.sleep(5)
    except KeyboardInterrupt:
        print("\nüëã Monitor interrompido")